---
title: "MATH3012: Chapter 1, Lecture 6"
date: ""
author: Helen Ogden
header-includes:
- \usepackage{bm}
- \usepackage{booktabs, multirow}
output:
  beamer_presentation
---


```{r, echo = FALSE}
knitr::opts_knit$set(root.dir = '../datasets')
```

## Recap

Last time, we

- found one of the most important results about the 
MLE: it has asymptotic 
$N(\theta, [{\cal I}(\theta)]^{-1})$ distribution.

How can we use this result to find confidence intervals 
for the parameters, and to test hypotheses?


## Constructing large sample confidence intervals

Asymptotically,
$\hat{\theta}_i \sim N(\theta_i,[\mathcal{I}(\bm \theta)^{-1}]_{ii})$ 
and we can find $z_{1-\frac{\alpha}{2}}$ such that
$$
P\left(z_{1-\frac{\alpha}{2}}\le {{\hat{\theta}_i-\theta_i}\over{[\mathcal{I}(\bm \theta)^{-1}]_{ii}^{1\over 2}}}\le
z_{1-\frac{\alpha}{2}}\right) = 1- \alpha.
$$
Therefore
$$
P\left(\hat{\theta}_i-z_{1-\frac{\alpha}{2}}[\mathcal{I}(\bm \theta)^{-1}]_{ii}^{1\over 2}\le\theta_i
\le\hat{\theta}_i+z_{1-\frac{\alpha}{2}}[\mathcal{I}(\bm \theta)^{-1}]_{ii}^{1\over 2}
\right) = 1- \alpha.
$$

## Constructing large sample confidence intervals

The endpoints of this interval cannot be evaluated
because they also depend on the unknown parameter vector $\bm \theta$.
However, if we replace $\mathcal{I}(\bm \theta)$ by its MLE ${\cal I}(\hat{\bm \theta})$
we obtain the approximate large sample $\bm{100(1 - \alpha)}\%$ confidence interval
$$
[\hat{\theta}_i-z_{1-\frac{\alpha}{2}}[{\cal I}(\hat{\bm \theta})^{-1}]_{ii}^{1\over 2},
\hat{\theta}_i+z_{1-\frac{\alpha}{2}}[{\cal I}(\hat{\bm \theta})^{-1}]_{ii}^{1\over 2}].
$$
For $\bm{\alpha=0.1,0.05,0.01}$, $z_{1-\frac{\alpha}{2}}=1.64,1.96,2.58$.

**Correct typo in notes.**

## Example (Bernoulli)
If $y_1, \ldots, y_n$ are observations of $Y_1, \ldots, Y_n$, i.i.d. Bernoulli$(p)$ random
variables then asymptotically $\hat{p}=\bar y$ has a  $N(p,{p(1-p)}/ n)$
distribution, and a large sample 95\% confidence interval
for $p$ is
\begin{align*}
& [\hat{p}- 1.96[{\cal I}(\hat{p})^{-1}]^{1\over 2},
\hat{p}+1.96[{\cal I}(\hat{p})^{-1}]^{1\over 2}]
\cr
&=
[\hat{p}-1.96[\hat{p}(1-\hat{p})/n]^{1\over 2},
\hat{p}+1.96[\hat{p}(1-\hat{p})/n]^{1\over 2}]\cr
&=
[\bar y-1.96[\bar y(1-\bar y)/n]^{1\over 2},
\bar y+1.96[\bar y(1-\bar y)/n]^{1\over 2}].
\end{align*}


## Comparing statistical models

Suppose we have a set of competing probability models
which might have generated the observed data. Which model
is most appropriate?

Suppose that we have two competing alternatives, $f^{(0)}_{\bm Y}$ (model
$H_0$) and $f^{(1)}_{\bm Y}$  (model $H_1$) for $f_{\bm Y}$,
the joint distribution of $Y_1, \ldots, Y_n$.

The most common situation is where $H_0$ and $H_1$
both take the same parametric form, $f_{\bm Y}(\bm{y};\bm \theta)$ but
with $\bm \theta\in\Theta^{(0)}$ for $H_0$ and $\bm \theta\in\Theta^{(1)}$ for $H_1$,
where $\Theta^{(0)}$ and $\Theta^{(1)}$ are alternative sets of possible values
for $\bm \theta$.

## Hypothesis testing

A hypothesis test provides a mechanism for comparing the two competing statistical
models, $H_0$ and $H_1$.

The null hypothesis $H_0$ is the reference model, and will be assumed to
be appropriate unless the observed data strongly indicate that $H_0$ is
inappropriate, and that $H_1$ (the *alternative* hypothesis) should be
preferred.

Hence, the fact that a hypothesis test does not reject $H_0$ should not be taken
as evidence that $H_0$ is true and $H_1$ is not, or that $H_0$ is  better
supported by the data than $H_1$, merely that the data does not provide
sufficient evidence to reject $H_0$ in favour of $H_1$.

## Critical region
A hypothesis test is defined by its *critical region* or 
*rejection region*, which we shall denote by $C$. 

- If $\bm{y} \in C$, $H_0$ is rejected in favour of $H_1$;
- If $\bm{y} \not\in C$, $H_0$ is not rejected.

## Size and power of a test

We define the *size* (or *significance level*) of the test
\[\alpha = \max_{\bm \theta\in\Theta^{(0)}}P(\bm Y\in C;\bm \theta)\]
This is the maximum probability of erroneously rejecting $H_0$, over all
possible distributions for $\bm Y$ implied by $H_0$.

We also define the power function 
\[\omega(\bm \theta)= P(\bm Y\in C;\bm \theta)\]
It represents the probability of rejecting $H_0$
for a particular value of $\bm \theta$.

A good test will
have small size, but large power.

## Fixing the size, maximising the power

In general, we fix $\alpha$ to be some small
value (often 0.05), so that the probability of erroneous rejection of $H_0$ is
limited. In doing this, we are giving $H_0$ precedence over $H_1$.

Given our specified $\alpha$, we try to choose a test
to make $\omega(\bm \theta)$ as large  as possible for
$\bm \theta\in\Theta^{(1)}\setminus\Theta^{(0)}$.


## Generalised likelihood ratio test

Suppose that $H_0$ and $H_1$ both take the same parametric form,
$f_{\bm Y}(\bm{y};\bm \theta)$ with $\bm \theta\in\Theta^{(0)}$ for $H_0$ and $\bm \theta\in\Theta^{(1)}$
for $H_1$, where $\Theta^{(0)}$ and $\Theta^{(1)}$ are alternative sets of
possible values for $\bm \theta$.

A *generalised likelihood ratio test* of $H_0$ against $H_1$ has a critical region
of the form
\[C=\left\{ \bm{y}: 
\frac{\max_{\bm \theta\in \Theta^{(1)}}L(\bm \theta)}
{\max_{\bm \theta\in \Theta^{(0)}}L(\bm \theta)} 
>k\right\}\]
where $k$ is determined by $\alpha$, the size of the test, so
\[\max_{\bm \theta\in\Theta^{(0)}}P(\bm{y}\in C;\bm \theta)=\alpha.\]
We only reject
$H_0$ if the observed data are
much more probable under some distribution in $H_1$ 
than any distribution under $H_0$.

## Example (Bernoulli)
$y_1, \ldots, y_n$ are observations of $Y_1, \ldots, Y_n$, i.i.d. Bernoulli$(p)$ random
variables. Suppose that we require a size $\alpha$ test of the hypothesis
$H_0$: $p=p_0$ against the general alternative $H_1$: '$p$ is unrestricted' where
$\alpha$ and
$p_0$ are specified.

Here $\bm \theta=(p)$, $\Theta^{(0)}=\{p_0\}$ and $\Theta^{(1)}=(0,1)$ and the
generalised likelihood ratio test rejects $H_0$ when
\[{{\max_{p\in(0,1)}L(p)}\over{\max_{p=p_0}L(p)}} > k\]
or equivalently when
\[{{\bar y^{\sum_i y_i}(1-\bar y)^{n-\sum_i y_i}}\over {p_0^{\sum_i y_i}(1-p_0)^{n-\sum_i y_i}}} > k.\]

## Finding an equivalent critical region.
We reject $H_0$ when
\[{{\bar y^{\sum_i y_i}(1-\bar y)^{n-\sum_i y_i}}\over {p_0^{\sum_i y_i}(1-p_0)^{n-\sum_i y_i}}} > k.\]
Equivalently
\begin{equation}
\left({{\bar y}\over{p_0}}\right)^{n\bar y}
\left({{1-\bar y}\over{1-p_0}}\right)^{n(1-\bar y)} >k. 
\label{eq:her1}
\end{equation}
Now the left hand side of \eqref{eq:her1} is minimised as a function of $\bar y$
at $\bar y=p_0$ and increases as
$\bar y$ moves away from $p_0$ in either direction.
Therefore, the rejection region \eqref{eq:her1} is equivalent to
$$
C=\left\{ \bm{y}:\bar y > k' \text{ or } \bar y < k''\right\}
$$
where $k'$ and $k''$ are chosen so that
$$
P(\bm{y}\in C;p_0)=\alpha.
$$

## Choosing the cutoff points for the critical region
We want to choose $k'$ and $k''$ so that
if $Y_i \sim \text{Bernoulli}(p_0)$ then
\[P(\bar Y > k' \text{ or } \bar Y < k'')=\alpha.\]
or
\[P(k'' \leq \bar Y \leq k') = 1 - \alpha\]
or
\[P(n k'' \leq \sum_{i=1}^n Y_i \leq n k') = 1 - \alpha.\]
Therefore, we can use the binomial$(n,p_0)$ distribution to find a precise rejection
region for a test of specified size $\alpha$.



## The log-likelihood ratio statistic

A *generalised likelihood ratio test* of $H_0$ against $H_1$ has a critical region
of the form
$$
C=\left\{ \bm{y}:{{\max_{\bm \theta\in \Theta^{(1)}} L(\bm \theta)}\over
{\max_{\bm \theta\in \Theta^{(0)}}L(\bm \theta)}} >k\right\}
$$
where $k$ is determined by $\alpha$, the size of the test, so
$$
\max_{\bm \theta\in\Theta^{(0)}}P(\bm{y}\in C;\bm \theta)=\alpha.
$$

Therefore, in order to determine $k$, we need
to know the distribution of the likelihood ratio, or an equivalent statistic,
under $H_0$.
In general, this will not be available to us.
However, we can make use of an important asymptotic result.

## The log likelihood ratio statistic

First we notice that, as $\log$ is a strictly increasing function, the rejection
region is equivalent to

$$
C=\left\{ \bm{y}: 2\log \left({{\max_{\bm \theta\in \Theta^{(1)}}L(\bm \theta)}\over
{\max_{\bm \theta\in \Theta^{(0)}}L(\bm \theta)}}\right) >k'\right\}
$$
where
$$
\max_{\bm \theta\in\Theta^{(0)}}P(\bm{y}\in C;\bm \theta)=\alpha.
$$
Now, provided that $H_0$ is *nested within* $H_1$, in other words
$\Theta^{(0)}\subset\Theta^{(1)}$ ($\Theta^{(0)}$ is a subspace of
$\Theta^{(1)}$) then under
$H_0$: $\bm \theta\in\Theta^{(0)}$, asymptotically as
$n\to\infty$
$$
L_{01}\equiv 2\log \left({{\max_{\bm \theta\in \Theta^{(1)}}L(\bm \theta)}\over
{\max_{\bm \theta\in \Theta^{(0)}}L(\bm \theta)}}\right)
$$
has a chi-squared distribution with degrees of freedom equal to the difference in
the dimensions of $\Theta^{(1)}$ and $\Theta^{(0)}$.
## Example (Bernoulli)
$y_1, \ldots, y_n$ are observations of $Y_1, \ldots, Y_n$, i.i.d. Bernoulli$(p)$ random
variables. Suppose that we require a size $\alpha$ test of the hypothesis
$H_0$: $p=p_0$ against the general alternative $H_1$: '$p$ is unrestricted' where
$\alpha$ and
$p_0$ are specified.

Here $\bm \theta=(p)$, $\Theta^{(0)}=\{p_0\}$ and $\Theta^{(1)}=(0,1)$ and the
log likelihood ratio statistic is
$$
L_{01}=2n\bar y\log\left({{\bar y}\over{p_0}}\right)
+2n(1-\bar y)\log\left({{1-\bar y}\over{1-p_0}}\right).
$$
As $d_1=1$ and $d_0=0$, under $H_0$, the log likelihood ratio statistic
has an asymptotic $\chi^2_1$ distribution.

## Finding the critical value

We reject $H_0$ if $L_01$ is 'too large' to have come from a
$\chi^2_1$ distribution.

If $\alpha = 0.05$, then we should reject $H_0$
if the test statistic is greater than 
the 95\% point of the
$\chi^2_1$ distribution:
```{r}
qchisq(0.95, df = 1)
```


## Conclusion

- We have seen how to use the asymptotic distribution of the MLE
  to construct (approximate) confidence intervals.
- We have written down the form of a generalised likelihood ratio test.
  In some scenarios, you can find a critical region for a generalised likelihood
  ratio test to give $P(\mathbf{Y} \in C | H_0) = \alpha$.
- More commonly, it is not possible to find this exactly.
  Instead, if we have nested hypotheses, we can compute the
  log-likelihood ratio test statistic, which will have approximately
  chi-squared distribution under $H_0$, for large samples.
- You should now be able to attempt exercises 1 and 2 on problem sheet 2.


