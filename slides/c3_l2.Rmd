---
title: "MATH3012: Chapter 3, Lecture 2"
date: ""
author: Helen Ogden
header-includes:
- \usepackage{bm}
- \usepackage{booktabs, multirow}
output:
  beamer_presentation
---


```{r, echo = FALSE}
knitr::opts_knit$set(root.dir = '../datasets')
```
## Recap

- A contingency table is  a cross-classification
of counts according to categorical variables.
- A contingency table is just a particular view of a dataset:
we can rewrite the data in "long" format, which looks like
the data frame we are familiar with.
- We can model the cell counts in a contingency table data using 
log-linear models, which are just Poisson GLMs with the (canonical)
log link function.

Let's return to an example to demonstrate these concepts.

## A contingency table of the `job` dataset, with margins

\scriptsize
\begin{center}
\begin{tabular}{lrrrrr}
\toprule
  & \multicolumn{4}{c}{Job Satisfaction}  & \\
  \cmidrule{2-5}
Income (\$) & Very Dissat. & A Little Dissat. & Moderately Sat. & Very Sat. &
{\bf Sum}\\
\midrule
<6000 & 20 & 24 & 80 & 82 & {\bf 206}\\
6000-15000 & 22 & 38 & 104 & 125 & {\bf 289}\\
15000-25000 & 13 & 28 & 81 & 113 & {\bf 235}\\
>25000 & 7 & 18 & 54 & 92 & {\bf 171}\\
{\bf Sum} & {\bf 62} & {\bf 108} & {\bf 319} & {\bf 412} & {\bf 901} \\
\bottomrule
\end{tabular}
\end{center}

\normalsize
The **one-way margins** represent the classification of items by
a single variable; income group and job satisfaction respectively.


## Log-linear models

If the table has $n$ cells, which we label $1,\ldots ,n$, then
the observed cell counts $y_1,\ldots ,y_n$ are assumed to be observations
of independent Poisson random variables $Y_1,\ldots ,Y_n$.

We denote the means of these Poisson random variables by $\mu_1,\ldots ,\mu_n$,
and model $log(\mu_i) = \eta_i$, where $\bm \eta$ is the linear predictor.

The explanatory variables in a log-linear model for contingency table data are
the cross-classifying variables. 
As these variables are categorical, they are
**factors**. As usual with factors, we can include interactions in the model
as well as just main effects. 

Such a model will describe how the expected count
in each cell depends on the classifying variables, and any interactions between
them. Interpretation of these models will be discussed later on.

## `job` dataset in long format

The original data structure of the `job` dataset is

\scriptsize
\begin{center}
\begin{tabular}{llr}
\toprule
Income & Satisfaction & Count\\
\midrule
<6000 & Very Dissatisfied & 20\\
<6000 & A Little Dissatisfied & 24\\
<6000 & Moderately Satisfied & 80\\
<6000 & Very Satisfied & 82\\
6000-15000 & Very Dissatisfied & 22\\
6000-15000 & A Little Dissatisfied & 38\\
6000-15000 & Moderately Satisfied & 104\\
6000-15000 & Very Satisfied & 125\\
15000-25000 & Very Dissatisfied & 13\\
15000-25000 & A Little Dissatisfied & 28\\
15000-25000 & Moderately Satisfied & 81\\
15000-25000 & Very Satisfied & 113\\
>25000 & Very Dissatisfied & 7\\
>25000 & A Little Dissatisfied & 18\\
>25000 & Moderately Satisfied & 54\\
>25000 & Very Satisfied & 92\\
\bottomrule
\end{tabular}
\end{center}


## Log-linear models for `job`

The original format of the `job` dataset the same data 
as the contingency table,
but in a different format, sometimes called **long** format.

A log-linear model is just a Poisson GLM, where
the response variable is `Count`, and `Income`
and `Satisfaction` are explanatory variables.

```{r, include = FALSE}
job <- read.csv("job.csv")
job$Income <- factor(job$Income, levels = c("<6000", "6000-15000", "15000-25000", ">25000"))
job$Satisfaction <- factor(job$Satisfaction, 
levels = c("Very Dissatisfied", "A Little Dissatisfied", "Moderately Satisfied", "Very Satisfied"))
```
```{r}
loglin_job_1 <- glm(Count ~ Income + Satisfaction, 
                    family = poisson, data = job)
loglin_job_2 <- glm(Count ~ Income * Satisfaction, 
                    family = poisson, data = job)
```

## Looking at the fitted models

\scriptsize
```{r}
loglin_job_1
```
## Expected cell counts  ([web.meetoo.com](https://web.meetoo.com), 108-197-366)

\scriptsize
```{r}
coef(loglin_job_1)
```
\normalsize

The fitted values $\hat \mu_i = \exp(\bm x_i^T \hat {\bm \beta})$
give us the
expected counts in each cell of the contingency table.


Which of the following would give the expected
count of people with income $<6000$ who
were A Little Dissatisfied
under model `loglin_job_1`?

- $\exp(0.5550) = 1.7$
- $\exp(2.6515) = 14.1$
- $\exp(3.2065) = 24.7$

## Expected cell counts in contingency table format

\scriptsize
```{r}
fit1_tab <- xtabs(fitted(loglin_job_1) ~ Income + Satisfaction,
                  data = job)
addmargins(fit1_tab)
```

## Observed counts in contingency table format

\scriptsize
```{r}
job_tab <- xtabs(Count ~ Income + Satisfaction,
                 data = job)
addmargins(job_tab)
```

## Fitted coefficients for `loglin_job_2`

\tiny
```{r}
coef(loglin_job_2)
```

## Expected cell counts ([web.meetoo.com](https://web.meetoo.com), 108-197-366)

\scriptsize
```{r}
loglin_job_2 <- glm(Count ~ Income * Satisfaction, 
                    family = poisson, data = job)
```
\normalsize
There are $24$ people with income $<6000$ who
were A Little Dissatisfied. The expected count in 
this cell under model `loglin_job_1` is $24.7$.
What is the expected count in this cell under
`loglin_job_2`?

- less than $23.9$
- $24$
- between $24.1$ and $24.6$
- $24.7$
- more than $24.8$
- It is not possible to say




## Multinomial sampling

Although the assumption of Poisson distributed observations is convenient
for the purposes of modelling, it might not be a realistic assumption, because of
the way in which the data have been collected.

Frequently, when contingency table data are obtained, the total number of
observations (the *grand total*, the sum of all the cell counts) is fixed
in advance.

In this case, no individual cell count can exceed the prespecified fixed total,
so the assumption of Poisson sampling is invalid as the sample space
is bounded. Furthermore, with a fixed total, the observations can no
longer be observations of independent random variables.

## Recap: the `lymphoma` dataset

The `lymphoma` dataset gives information about 30 patients, classified
by cell type of lymphoma, sex, and response to treatment. This is an example of a
three-way contingency table. It is a $2\times 2\times 2$ or $2^3$ table.

\begin{center}
\begin{tabular}{lrrr}
\toprule
 & & \multicolumn{2}{c}{Remission} \\
 \cmidrule{3-4}
Cell Type & Sex  & No & Yes\\
\midrule
\multirow{2}{*}{Diffuse} & Female & 3 & 1\\
 & Male & 12 & 1\\
 \midrule
\multirow{2}{*}{Nodular} & Female & 2 & 6\\
 & Male & 1 & 4\\
\bottomrule
\end{tabular}
\end{center}

## `lymphoma` contingency table example
For the `lymphoma` contingency table, the appropriate
model to use depends on the process by which these data were collected:

- if the data were collected over a fixed period of time,
and that in that time there happened to be 30 patients, then
Poisson assumption is perfectly valid. 
- if it had been decided
at the outset to collect data on 30 patients,
the grand total is fixed at 30, and the Poisson assumption is not valid.

## The multinomial distribution

When the grand total is fixed, a more appropriate distribution for the
cell counts is the *multinomial* distribution.

The multinomial distribution is the distribution of cell counts arising
when a prespecified total of $N$ items are each independently assigned to
one of $n$ cells, where the probability of being classified into cell
$i$ is $p_i$, ${i=1,\ldots ,n}$, so $\sum_{i=1}^n p_i=1.$

The probability function for the multinomial distribution is
\vspace{-1cm}
\begin{align*}
f_{\bm{Y}}(\bm{y};{\bf p})
&= P(Y_1=y_1,\ldots ,Y_n=y_n) \cr
&= \begin{cases} 
N!\prod_{i=1}^n \frac{p_i^{y_i}}{y_i!} & \text{if $\sum_{i=1}^n y_i=N$} \\
0 & \text{otherwise.}
\end{cases}
\end{align*}
The binomial is the special
case of the multinomial with two cells ($n=2$).

## A multinomial log-linear model

When the data
have been obtained by multinomial sampling, we suppose
$\bm Y \sim \text{Multinomial}(N, \bm p)$, where
$\log\mu_i=\log(Np_i)$, ${i=1,\ldots ,n}$ 
is modelled as as a linear function of
explanatory variables.
Such a model must preserve $\sum_{i=1}^n \mu_i=N$, the grand total
which is fixed in advance.

\pause

The log-likelihood for a multinomial log-linear model is
$$
\ell(\bm{\mu})=
\sum_{i=1}^n y_i\log\mu_i -N\log N -\sum_{i=1}^n \log y_i!+\log N!.
$$

The maximum likelihood estimates $\hat{\bm{\mu}}$ maximise
$\sum_{i=1}^n y_i\log\mu_i$ subject to the constraints
$\sum_{i=1}^n \mu_i=N=\sum_{i=1}^n y_i$ (multinomial sampling) and
$\log\bm{\mu}=\bm{X}\bm{\beta}$ (imposed by the model).

## Inference in a Poisson log-linear model
For a Poisson log-linear model,
$$
L(\bm{\mu})=\prod_{i=1}^n {{e^{-\mu_i} \mu_i^{y_i}}\over{y_i!}}.
$$

Therefore
\vspace{-1cm}
\begin{align*}
\ell(\bm{\mu})&=-\sum_{i=1}^n \mu_i
+\sum_{i=1}^ny_i\log\mu_i-\sum_{i=1}^n \log y_i!
\\
&=-\sum_{i=1}^n \exp(\log\mu_i)
+\sum_{i=1}^ny_i\log\mu_i-\sum_{i=1}^n \log y_i!.
\end{align*}

## Poisson log-linear model with an intercept
Any Poisson log-linear model with an intercept can be expressed as
\[\log\mu_i=\alpha + \text{other terms depending on $i$},\qquad {i=1,\ldots ,n}
\]
so that
\vspace{-1cm}
\begin{align*}
&\qquad{\partial\over{\partial\alpha}} \ell(\bm{\mu})=-\sum_{i=1}^n \exp(\log\mu_i)
+\sum_{i=1}^ny_i. \\
&\Rightarrow\qquad \sum_{i=1}^n \hat{\mu}_i=\sum_{i=1}^n y_i.
\end{align*}
At $\alpha=\hat{\alpha}$ the log-likelihood takes the
form
$$
\ell(\bm{\mu})=-\sum_{i=1}^n y_i
+\sum_{i=1}^ny_i\log{\mu}_i-\sum_{i=1}^n \log y_i!.
$$

Hence, when we maximise the log-likelihood for a Poisson log-linear model with
intercept with respect to the other parameters, we are
maximising
$\sum_{i=1}^ny_i\log{\mu}_i$ subject to the constraints
$\sum_{i=1}^n \mu_i=\sum_{i=1}^n y_i$
and $\log\bm{\mu}=\bm{X}\bm{\beta}$.

## Equivalence of multinomial and Poisson log-linear inference

The maximum likelihood estimates for multinomial log-linear
parameters are identical to those for Poisson log-linear parameters.
Furthermore, the maximised log-likelihoods for both Poisson and multinomial
models take the form $\sum_{i=1}^ny_i\log\hat{\mu}_i$ as functions of
the log-linear parameter estimates.

So any inferences based on maximised log-likelihoods (such as likelihood
ratio tests) will be the same.

Therefore, we can analyse contingency table data using Poisson log-linear
models, even when the data has been obtained by multinomial sampling.
All that is required is that we ensure that the Poisson model
contains an intercept term.


## Conclusion

- We have revised the idea of a contingency table: a cross-classification
of counts according to categorical variables.
- A log-linear model is a Poisson GLM with the canonical link function (the 
log link). We can use log-linear models to model contingency table data,
and find expected cell counts.
- If the total count is fixed, a multinomial model is
more natural than a Poisson one, but we have shown that we make the same
conclusions about the relationships between variables with either model
(provided that we include an intercept in the Poisson model).
- Next time, we'll see an extension to the multinomial model in which one
of the one-way margins is fixed.
- Reminder: the coursework deadline is 5pm on Wednesday. 
I have an additional office hour 2:30-3:30pm today, in the Maths
Student Centre.
