---
title: "MATH3012 problem sheet 1"
author: ""
date: ""
output: pdf_document
fontsize: 12pt
header-includes:
- \newcommand{\benum}{\begin{enumerate}}
- \newcommand{\eenum}{\end{enumerate}}
- \usepackage{bm}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\benum

\item Assume that $y_1, \ldots, y_n$ are observations from i.i.d. $\text{Poisson}(\lambda)$ random variables $Y_1, \ldots, Y_n$. 
Find the maximum likelihood estimate of $\lambda$.

\item Suppose $y_1,y_2,\cdots,y_n$ are observations from
random variables $Y_1, \ldots, Y_n$, which are i.i.d. with p.d.f.
(or p.f.) $f_Y(y; \theta)$ for a scalar parameter $\theta$.
In each case below, derive the maximum likelihood estimate of $\theta$,
and find the score and Fisher information.
\benum
\item $f_Y(y; \theta) = \theta \exp(-\theta y)$, $y > 0$, $\theta > 0$ (exponential distribution);
\item $f_Y(y; \theta) = \theta y^{\theta - 1}$, $y \in (0, 1)$, $\theta > 0$;
\item $f_Y(y; \theta) = \theta(1 - \theta)^{y - 1}$, $y \in \{1, 2, 3, \ldots\}$,
$\theta \in (0, 1)$
(geometric distribution).
\eenum

\item For the simple linear regression model, $Y_i \sim N(\beta_0+\beta_1x_i, \sigma^2)$, where $Y_1, \ldots, Y_n$ are independent:
\benum
\item find the maximum likelihood estimators of $\beta_0$ and $\beta_1$. 
You may assume that a stationary point of the log-likelihood
is a maximum.

\item find the maximum likelihood estimator of $\sigma^2$.
You may assume that a stationary point of the log-likelihood
is a maximum.

\item write down the maximum likelihood estimator of $\sigma$.

\eenum

\item In each of the cases from question 2, use the fact that
the expected score is zero to find an unbiased estimator of $\theta^{-1}$.

\eenum
